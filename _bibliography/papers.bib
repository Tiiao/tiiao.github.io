---
---

###################
#--- Preprints ---#
###################

@article{sheen2024implicit,
  title={Implicit regularization of gradient flow on one-layer softmax attention},
  author={Sheen, Heejune and Chen, Siyu and Wang, Tianhao and Zhou, Harrison H.},
  abbr={arXiv},
  journal={arXiv:2403.08699},
  year={2024},
  arxiv={2403.08699},
  comments={Presented at ICLR 2024 Workshop on Bridging the Gap Between Practice and Theory in Deep Learning},
  selected={true},
  category={transformer},
  preprint={true}
}

@article{giannou2024how,
  title={How well can Transformers emulate in-context Newton's method?},
  author={Giannou, Angeliki and Yang, Liu and Wang, Tianhao and Papailiopoulos, Dimitris and Lee, Jason D.},
  abbr={arXiv},
  journal={arXiv:2403.03183},
  year={2024},
  comments={Presented at ICLR 2024 Workshop on Bridging the Gap Between Practice and Theory in Deep Learning},
  arxiv={2403.03183},
  selected={true},
  category={transformer},
  preprint={true}
}

######################
#--- Publications ---#
######################

@inproceedings{chen2024unveiling,
  title={Unveiling Induction Heads: Provable Training Dynamics and Feature Learning in Transformers},
  author={Chen, Siyu and Sheen, Heejune and Wang, Tianhao and Yang, Zhuoran},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2024},
  arxiv={2409.10559},
  selected={true},
  category={transformer},
  preprint={false},
}

@article{zhong2021approximate,
  title={Approximate Message Passing for orthogonally invariant ensembles: Multivariate non-linearities and spectral initialization},
  author={Zhong, Xinyi and Wang, Tianhao and Fan, Zhou},
  equal={12},
  abbr={arXiv},
  journal={Information and Inference: A Journal of the IMA},
  year={2024},
  arxiv={2110.02318},
  selected={true},
  category={AMP},
  preprint={false}
}

@article{wang2022universality,
  title={Universality of Approximate Message Passing algorithms and tensor networks},
  author={Wang, Tianhao and Zhong, Xinyi and Fan, Zhou},
  abbr={arXiv},
  journal={The Annals of Applied Probability},
  year={2024},
  link={https://projecteuclid.org/journals/annals-of-applied-probability/volume-34/issue-4/Universality-of-approximate-message-passing-algorithms-and-tensor-networks/10.1214/24-AAP2056.full},
  arxiv={2206.13037},
  selected={true},
  category={AMP},
  preprint={false}
}

@article{chen2024training,
  title={Training dynamics of multi-head softmax attention for in-context learning: emergence, convergence, and optimality},
  author={Chen, Siyu and Sheen, Heejune and Wang, Tianhao and Yang, Zhuoran},
  abbr={arXiv},
  journal={Conference on Learning Theory (COLT)},
  year={2024},
  comments={Presented at ICLR 2024 Workshop on Bridging the Gap Between Practice and Theory in Deep Learning},
  arxiv={2402.19442},
  selected={true},
  category={transformer},
  preprint={false}
}

@article{fan2021maximum,
  title={Maximum likelihood for high-noise group orbit estimation and single-particle cryo-EM},
  author={Fan, Zhou and Lederman, Roy R. and Sun, Yi and Wang, Tianhao and Xu, Sheng},
  abbr={arXiv},
  journal={The Annals of Statistics},
  year={2024},
  link={https://projecteuclid.org/journals/annals-of-statistics/volume-52/issue-1/Maximum-likelihood-for-high-noise-group-orbit-estimation-and-single/10.1214/23-AOS2292.short},
  arxiv={2107.01305},
  selected={true},
  category={orbit recovery},
  preprint={false}
}

@inproceedings{wang2023marginal,
  title={The Marginal Value of Momentum for Small Learning Rate SGD},
  author={Wang, Runzhe and Malladi, Sadhika and Wang, Tianhao and Lyu, Kaifeng and Li, Zhiyuan},
  abbr={ICLR},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024},
  link={https://openreview.net/forum?id=3JjJezzVkT},
  arxiv={2307.15196},
  selected={true},
  category={optimization},
  preprint={false},
}

@inproceedings{xu2023noise,
  title={Noise-adaptive Thompson sampling for linear contextual bandits},
  author={Xu, Ruitu and Min, Yifei and Wang, Tianhao},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2023},
  link={https://openreview.net/forum?id=BnV2M2WFaY},
  selected={false},
  category={reinforcement learning},
  preprint={false},
}

@inproceedings{min2023cooperative,
  title={Cooperative multi-Agent reinforcement learning: asynchronous communication and linear function approximation},
  author={Min, Yifei and He, Jiafan and Wang, Tianhao and Gu, Quanquan},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2023},
  arxiv={2305.06446},
  category={reinforcement learning},
  preprint={false},
}

@inproceedings{xu2022finding,
  title={Finding regularized competitive equilibria of heterogeneous agent macroeconomic models via reinforcement learning},
  author={Xu, Ruitu and Min, Yifei and Wang, Tianhao and Jordan, Michael I. and Wang, Zhaoran and Yang, Zhuoran},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year={2022},
  category={reinforcement learning},
  preprint={false}
}

@inproceedings{li2022fast,
  title={Fast mixing of stochastic gradient descent with normalization and weight decay},
  author={Li, Zhiyuan and Wang, Tianhao and Yu, Dingli},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022},
  selected={true},
  category={optimization},
  preprint={false}
}

@inproceedings{min2022learn,
  title={Learn to match with no regret: Reinforcement learning in Markov matching markets},
  author={Min, Yifei and Wang, Tianhao and Xu, Ruitu and Wang, Zhaoran and Jordan, Michael I and Yang, Zhuoran},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  highlight={Oral},
  year={2022},
  arxiv={2203.03684},
  category={reinforcement learning},
  preprint={false}
}

@inproceedings{he2022simple,
  title={A simple and provably efficient algorithm for asynchronous federated contextual linear bandits},
  author={He, Jiafan and Wang, Tianhao and Min, Yifei and Gu, Quanquan},
  equal={123},
  abbr={NeurIPS},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022},
  arxiv={2207.03106},
  selected={true},
  category={reinforcement learning},
  preprint={false}
}

@inproceedings{li2022implicit,
  title={Implicit bias of gradient descent on reparametrized models: On equivalence to mirror descent},
  author={Li, Zhiyuan and Wang, Tianhao and Lee, Jason D. and Arora, Sanjeev},
  equal={12},
  abbr={NeurIPS},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  arxiv={2207.04036},
  year={2022},
  selected={true},
  category={optimization},
  preprint={false},
  comments={Abridged version accepted for a contributed talk to <a href="https://sites.google.com/view/continuous-time-methods-icml/home">ICML 2022 Workshop on Continuous time methods for machine learning</a>},
  slides={commuting_slides.pdf},
  poster={commuting_poster.pdf}
}

@inproceedings{min2021learning,
  title={Learning stochastic shortest path with linear function approximation},
  author={Min, Yifei and He, Jiafan and Wang, Tianhao and Gu, Quanquan},
  abbr={ICML},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2022},
  organization={PMLR},
  link={},
  arxiv={2110.12727},
  category={reinforcement learning},
  preprint={false},
  slides={SSP_slides.pdf},
  poster={SSP_poster.pdf}
}

@inproceedings{li2021happens,
  title={What happens after SGD reaches zero loss?--A mathematical framework},
  author={Li, Zhiyuan and Wang, Tianhao and Arora, Sanjeev},
  abbr={ICLR},
  highlight={Spotlight},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2022},
  link={https://openreview.net/forum?id=siCt4xZn5Ve},
  arxiv={2110.06914},
  selected={true},
  category={optimization},
  preprint={false},
  slides={diffusion_manifold_slides.pdf},
  poster={diffusion_manifold_poster.pdf}
}

@article{valentino2022north,
  title={North American biliary stricture management strategies in children after liver transplantation: a multicenter analysis from the society of pediatric liver transplantation (SPLIT) registry},
  author={Valentino, Pamela L and Wang, Tianhao and Shabanova, Veronika and Ng, Vicky Lee and Bucuvalas, John C and Feldman, Amy G and Gonzalez-Peralta, Regino P and Gupta, Nitika Arora and Miloh, Tamir A and Mohammad, Saeed and others},
  abbr={Journal},
  journal={Liver Transplantation},
  volume={28},
  number={5},
  pages={819--833},
  year={2022},
  publisher={Wiley Online Library},
  link={https://aasldpubs.onlinelibrary.wiley.com/doi/abs/10.1002/lt.26379},
  preprint={false}
}

@inproceedings{min2021variance,
  title={Variance-aware off-policy evaluation with linear function approximation},
  author={Min, Yifei and Wang, Tianhao and Zhou, Dongruo and Gu, Quanquan},
  equal={12},
  abbr={NeurIPS},
  booktitle={Advances in neural information processing systems (NeurIPS)},
  volume={34},
  pages={7598--7610},
  year={2021},
  link={https://proceedings.neurips.cc/paper/2021/hash/3e6260b81898beacda3d16db379ed329-Abstract.html},
  arxiv={2106.11960},
  category={reinforcement learning},
  preprint={false},
  slides={VAOPE_slides.pdf},
  poster={VAOPE_poster.pdf}
}

@inproceedings{wang2021provably,
  title={Provably efficient reinforcement learning with linear function approximation under adaptivity constraints},
  author={Wang, Tianhao and Zhou, Dongruo and Gu, Quanquan},
  equal={12},
  abbr={NeurIPS},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={34},
  pages={13524--13536},
  year={2021},
  link={https://proceedings.neurips.cc/paper/2021/hash/70a32110fff0f26d301e58ebbca9cb9f-Abstract.html},
  arxiv={2101.02195},
  category={reinforcement learning},
  preprint={false},
  slides={LSC_slides.pdf},
  poster={LSC_poster.pdf}
}

@article{fan2020likelihood,
  title={Likelihood landscape and maximum likelihood estimation for the discrete orbit recovery model},
  author={Fan, Zhou and Sun, Yi and Wang, Tianhao and Wu, Yihong},
  abbr={CPAM},
  journal={Communications on Pure and Applied Mathematics},
  publisher={Wiley Online Library},
  year={2022},
  link={https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.22032},
  arxiv={2004.00041},
  category={orbit recovery},
  preprint={false}
}

@inproceedings{xu2018continuous,
  title={Continuous and discrete-time accelerated stochastic mirror descent for strongly convex functions},
  author={Pan Xu and Tianhao Wang and Quanquan Gu},
  equal={12},
  abbr={ICML},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={5492--5501},
  year={2018},
  organization={PMLR},
  link={https://proceedings.mlr.press/v80/xu18g.html},
  category={optimization},
  preprint={false}
}

@inproceedings{xu2018accelerated,
  title={Accelerated stochastic mirror descent: From continuous-time dynamics to discrete-time algorithms},
  author={Xu, Pan and Wang, Tianhao and Gu, Quanquan},
  equal={12},
  abbr={AISTATS},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={1087--1096},
  year={2018},
  organization={PMLR}, 
  link={https://proceedings.mlr.press/v84/xu18e.html},
  category={optimization},
  preprint={false}
}